{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Required Packages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Table of Contents\n",
    "\n",
    "    1.0 Loading the Dataset\n",
    "    \n",
    "    1.1 Working without Duplicates\n",
    "        1.1.1 Selecting Distinct Observations by removing duplicates.\n",
    "        1.1.2 Counting distinct records.\n",
    "        1.1.3 Selecting Top 10.\n",
    "        1.1.4 Selecting with multiple conditions.\n",
    "        1.1.5 Selecting only the required columns.\n",
    "        \n",
    "    1.2 Using Where Statement as a Filter\n",
    "        1.2.1 Where statement\n",
    "        1.2.3 Having as an extra filter\n",
    "    \n",
    "    1.3 Tables Joinings and Merging\n",
    "        1.3.1 Inner Join\n",
    "        1.3.2 Left Join\n",
    "        1.3.3 Right Join\n",
    "        1.3.4 Self Join\n",
    "        1.3.5 Union\n",
    "        1.3.6 Union All\n",
    "    \n",
    "    1.4 Creating new features using Case Statement \n",
    "    \n",
    "    1.5 Sort Records\n",
    "        1.5.1 Sorting Records in Ascending order\n",
    "        1.5.2 Sorting Records in \n",
    "        \n",
    "    1.6 Matching Certain String\n",
    "        1.6.1 Containing\n",
    "        1.6.2 Like\n",
    "        1.6.3 Startwith\n",
    "        1.6.4 Endwith\n",
    "        \n",
    "    1.7 Converting a table from Flat to Wide uisng Case statement.\n",
    "    \n",
    "    1.8 Using Group by statement\n",
    "    \n",
    "    1.9 Window Functions\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.0 Loading the Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pandasql import sqldf\n",
    "import json\n",
    "import os\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "pd.options.display.float_format = '{:.2f}'.format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function to glimpse the data\n",
    "def glimpse(df):\n",
    "    display(df.info())\n",
    "    display(df.head())\n",
    "    display(df.describe())\n",
    "    #print(f\"{df.shape[0]} rows and {df.shape[1]} columns\")\n",
    "\n",
    "def check_missing_data(df):\n",
    "    missing_columns = df.columns[df.isnull().any()].tolist()\n",
    "    if len(missing_columns) > 0:\n",
    "        print(\"Columns with missing data:\")\n",
    "        for col in missing_columns:\n",
    "            missing_rows = df[col].isnull().sum()\n",
    "            print(f\"{col}: {missing_rows} missing rows\")\n",
    "    else:\n",
    "        print(\"No columns have missing data.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Datasets for Use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data (will download the data if it's the first time loading)\n",
    "housing = fetch_california_housing(as_frame=True)\n",
    "# Create a dataframe\n",
    "df_0 = housing['data'].join(housing['target'])\n",
    "glimpse(df_0)\n",
    "check_missing_data(df_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1 = pd.read_csv(\"https://media.geeksforgeeks.org/wp-content/uploads/nba.csv\")\n",
    "# dropping null value columns to avoid errors\n",
    "df_1.dropna(inplace = False)\n",
    "glimpse(df_1)\n",
    "check_missing_data(df_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'http://universities.hipolabs.com/search?'\n",
    "# Load the first sheet of the JSON file into a data frame\n",
    "df_2 = pd.read_json(url, orient='columns').applymap(str)\n",
    "df_2 = df_2.applymap(str)\n",
    "glimpse(df_2)\n",
    "check_missing_data(df_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select * from df_3 where upper(substring(name,2,2)) = 'ER'  \n",
    "# substring to be searched\n",
    "sub ='er'\n",
    "\n",
    "# start var\n",
    "start = 2\n",
    "\n",
    "# creating and passing series to new column\n",
    "df_2[\"Indexes\"] = df_2[\"name\"].str.find(sub, start)\n",
    " \n",
    "# display\n",
    "df_2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select * from df_2 where upper(substring(name,2,2)) = 'ER'\n",
    "\n",
    "result = df_2[df_2['name'].str[1:3].str.upper() == 'ER']\n",
    "result.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  select * from df_3 where upper(name) like %COLLEGE% and country <> 'United States'\n",
    "\n",
    "result = df_2[(df_2['name'].str.upper().str.contains('COLLEGE')) & (df_2['country'] != 'United States')]\n",
    "result.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Working without duplicates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1.1 selecting distinct observation from the record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#select distinct name, country, alpha_two_code from df_3\n",
    "ds_df = df_2[['country','alpha_two_code','name']].drop_duplicates()\n",
    "ds_df.head()\n",
    "len(ds_df.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The fact that distinct name is chosen \n",
    "sqldf(\"select count(name) as vol from (select distinct name, country, alpha_two_code from df_2)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sqldf(\"select count(distinct name) as total from df_2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sqldf(\"select * from df_3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Name\tTeam\tNumber\tPosition\tAge\tHeight\tWeight\tCollege\tSalary"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Out of the 9782 records in df_3, there are 10 duplicated records, which leafs us with 9772 records after we have removed the dupplicates."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1.2 Counting distinct records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#select country, count(country) as total from df_dist order by total desc\n",
    "df_3['country'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sqldf(\"select country, count(*) as Total from df_3 group by country order by Total desc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#select country, count (*) as total from (select distinct name, country, alpha_two_code from df_3) group by country order by total desc\n",
    "out = df_3[['country','alpha_two_code','name']].drop_duplicates()\n",
    "out['country'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sqldf(\"select country, count(distinct name) as Total from df_3 group by country order by Total desc\")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "from the above it seems all of the duplicated records are from United States. Let us filter down on United States to have glimpse of the duplicated records.\n",
    "\n",
    "Our expectation is that, the table is suppsoed to have a one record for each school. So, why are we having more than 1 records for some schools?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To see all of the records of the duplicates\n",
    "#select country, count(*) as total from (select distinct name, country, alpha_two_code from df_3) group by country having total > 1 \n",
    "t1 = df_3[df_3['country']=='United States']\n",
    "t1['name'].value_counts()[t1['name'].value_counts()>1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_3[(df_3['country']=='United States') & ((df_3['name']=='Highland Community College') | (df_3['name']=='Southwestern Community College')) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sqldf(\"select * from df_3 where country = 'United States' and name in ('Highland Community College','Southwestern Community College')\")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "We can see that Highland Community College and Southwestern Community College has got 2 records instead of 1 and that is because these schools has got more than 1 web_page i.e Highland Community College - ([http://www.highland.edu],[http://www.highlandcc.edu]) and Southwestern Community College - ([http://www.swcciowa.edu],[http://www.southwesterncc.edu]).\n",
    "\n",
    "This has now provide reasons for the duplicates."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1.3 Selecting Top 10 countries by number of Universities without duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#select country, count(country) as counts from df_dist order by counts desc limit 10\n",
    "t_0 = df_3[['country','alpha_two_code','name']].drop_duplicates()\n",
    "t_0 = t_0['country'].value_counts().rename_axis('country').reset_index(name='counts')\n",
    "t_0['percent'] = t_0['counts']/t_0['counts'].sum()\n",
    "t_0['percent'] = t_0['percent'].map('{:.2%}'.format)\n",
    "t_0.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sqldf(\"select country,count\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1.4 selecting a variable and calculating the mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#select Team, avg(Salary) as AvgSalary from df_2 where Salary != '' group by Team order by AvgSalary desc Limit 10;\n",
    "t_f = df_2[['Team','Salary']].groupby('Team').mean().dropna().reset_index()\n",
    "t_f.sort_values(by=['Salary'], inplace=True, ascending=False)\n",
    "t_f.head(10)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Using SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sqldf(\"select team,count(*)as vol,sum(salary) as total_sal, avg(Salary) as avg_sal from df_2 where Salary != '' group by Team order by avg_sal desc limit 10\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#select Team, Name, max(Salary) as Salary from df_2 group by Team,Name order by Salary desc limit 10\n",
    "tt = df_2[['Name','Team','Salary']].groupby(['Team','Name']).max().dropna().reset_index()\n",
    "tt.sort_values(by=['Salary'], inplace=True, ascending=False)\n",
    "tt.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sqldf(\"select Team, Name, max(Salary) as Salary from df_2 group by Team,Name order by Salary desc limit 10\")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "From the report above, Tony Wroten of the New York Knicks is the highest paying Players with a salary of $22.875m."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#select max(Salary) from df_2 where age = 20\n",
    "df_2[df_2.Team == 'New York Knicks']['Salary'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sqldf(\"select max(salary) as Max_Sal from df_2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#which team has the highest "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.3.1 Inner Join using a Key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_inner = pd.merge(left=df, right=df_1, left_on='ClientID', right_on='ClientID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_inner.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(df_inner)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *** Selecting only the required columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_inner_1 = df_inner[['ClientID','LoanDate','LoanAmount','Term','LoanSeries','LoanPeriodID','RepaymentTerm','InterestAmount',\n",
    " 'Age','year_with_the_bank','default','predicted_scores','Defaulted_0','Defaulted_1']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_inner_1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_inner_1.to_csv('C:\\\\Users\\\\seune\\\\desktop\\\\base_scoring_1.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *** Selecting with multiple conditions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_sql = np.where((df['LoanDate']>='8/8/2017') & (df['LoanAmount'] > 50000) & (df['FT_Team'].str.startswith('S')))\n",
    "\n",
    "#Select * from df where LoanDate >= '8/8/2017' and LoanAmount > 50000 and Age > 30\n",
    "df_sql = np.where((df['LoanDate'] >= '8/8/2017') & (df['LoanAmount'] > 50000) & (df['Age'] > 50))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sql_1 = df.loc[df_sql]\n",
    "df_sql_1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sql_1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sorting dataframe\n",
    "df_3.sort_values(\"Team\", inplace = True)\n",
    "\n",
    "df_3.dropna(inplace = True)\n",
    "  \n",
    "# making boolean series for a team name\n",
    "filter1 = df_3[\"Team\"]==\"Atlanta Hawks\"\n",
    "  \n",
    "# making boolean series for age\n",
    "filter2 = df_3[\"Age\"]>=27\n",
    "  \n",
    "# filtering data on basis of both filters\n",
    "df_3.where(filter1 & filter2, inplace = True)\n",
    "\n",
    "#.dropna(inplace = True)\n",
    "  \n",
    "# display\n",
    "df_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#select * from df_3 where Team = 'Atlanta Hawks'\n",
    "\n",
    "# sorting dataframe\n",
    "df_3.sort_values(\"Team\", inplace = True)\n",
    "  \n",
    "# making boolean series for a team name\n",
    "filter = df_3[\"Team\"]==\"Atlanta Hawks\"\n",
    "  \n",
    "# filtering data\n",
    "df_3.where(filter, inplace = True)\n",
    "  \n",
    "# display\n",
    "df_3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *** Selecting only records with Wildcard "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_distinct.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *** Where a strings starts with U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#select all record from the dataframe where name like University\n",
    "df_json_sql = np.where((df_distinct['alpha_two_code'] == 'US') & (df_distinct['name'].str.startswith('U')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_json_sql_1 = df_distinct.loc[df_json_sql]\n",
    "df_json_sql_1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_json_sql_1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#select all record from the dataframe where name ends with 'Uni'\n",
    "df_json1 = np.where((df_distinct['alpha_two_code'] == 'US') & (df_distinct['name'].str.endswith('Uni')))\n",
    "df_json_1 = df_distinct.loc[df_json1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *** Where a string contains 'Uni' and 'Was'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#select all record from the dataframe where name like Uni and name like Was\n",
    "df_json_s = np.where((df_json['name'].str.contains('Uni')) & (df_json['name'].str.contains('Was')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_json_s_1 = df_json.loc[df_json_s]\n",
    "df_json_s_1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_json_s_a = df_json[df_json['name'].str.contains('Uni') & df_json['name'].str.contains('Was')]\n",
    "df_json_s_a.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *** Select Country, alpha_two_code and count distinct Universities in each of the countries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_json.loc['country','alpha_two_code']\n",
    "\n",
    "df_3[['country','alpha_two_code']].agg(['nunique','count','size'])\n",
    "\n",
    "\n",
    "#.agg(['nunique','count','size'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_3.groupby(['country','alpha_two_code']).agg(['count', 'nunique']).stack()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ****Case when "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def myfunc(Start_Date,End_Date):\n",
    "    Full_Year_Goal = None\n",
    "    if (Start_Date >= '2014-07-27' or Start_Date == '2014-07-27') and End_Date <= '2015-07-25':\n",
    "        Full_Year_Goal = 'Y'\n",
    "    elif (Start_Date == '2015-07-26' or Start_Date == '2015-07-27') and End_Date == '2016-07-30':\n",
    "        Full_Year_Goal = 'Y'\n",
    "    elif (Start_Date == '2016-07-31' and End_Date == '2017-07-29'):\n",
    "        Full_Year_Goal = 'Y'\n",
    "    elif (Start_Date == '2017-07-30' or Start_Date == '2017-07-31') and End_Date == '2018-07-28':\n",
    "        Full_Year_Goal = 'Y'\n",
    "    else:\n",
    "        Full_Year_Goal = 'N'\n",
    "    return Full_Year_Goal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "myfunc(Start_Date = '2014-07-27',End_Date = '2015-07-22')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
