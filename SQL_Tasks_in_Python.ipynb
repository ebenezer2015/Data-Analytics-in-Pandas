{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Required Packages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Table of Contents\n",
    "\n",
    "    1.0 Loading the Dataset\n",
    "    1.1 Working without Duplicates\n",
    "        1.1.1 Selecting Distinct Observations by removing duplicates.\n",
    "        1.1.2 Counting distinct records.\n",
    "        1.1.3 Selecting Top 10.\n",
    "        1.1.4 Selecting with multiple conditions.\n",
    "        1.1.5 Selecting only the required columns.\n",
    "    1.2 Using Wild Cards\n",
    "        1.2.1 Containing\n",
    "        1.2.2 Like\n",
    "        1.2.3 Startwith\n",
    "        1.2.4 Endwith\n",
    "    1.3 Tables Joinings\n",
    "        1.3.1 Inner Join\n",
    "        1.3.2 Left Join\n",
    "        1.3.3 Right Join\n",
    "    1.4 Sort Records\n",
    "        1.4.1. \n",
    "    1.5 Case When \n",
    "    1.6 Converting a table from Flat to Wide uisng Case.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.0 Loading the Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pandasql import sqldf\n",
    "import json\n",
    "import os\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "pd.options.display.float_format = '{:.2f}'.format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function to glimpse the data\n",
    "def glimpse(df):\n",
    "    print(f\"{df.shape[0]} rows and {df.shape[1]} columns\")\n",
    "    display(df.head())\n",
    "    display(df.tail())\n",
    "    display(df.columns.values.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Datasets for Use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data (will download the data if it's the first time loading)\n",
    "housing = fetch_california_housing(as_frame=True)\n",
    "# Create a dataframe\n",
    "df = housing['data'].join(housing['target'])\n",
    "glimpse(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2 = pd.read_csv(\"https://media.geeksforgeeks.org/wp-content/uploads/nba.csv\")\n",
    "\n",
    "# dropping null value columns to avoid errors\n",
    "df_2.dropna(inplace = True)\n",
    "\n",
    "glimpse(df_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'http://universities.hipolabs.com/search?'\n",
    "# Load the first sheet of the JSON file into a data frame\n",
    "df_3 = pd.read_json(url, orient='columns')\n",
    "\n",
    "glimpse(df_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#select * from df_3 where upper(substring(name,2,2)) = 'ER'  \n",
    "# substring to be searched\n",
    "sub ='er'\n",
    " \n",
    "# start var\n",
    "start = 2\n",
    " \n",
    "# creating and passing series to new column\n",
    "df_3[\"Indexes\"]= df_3[\"name\"].str.find(sub, start)\n",
    " \n",
    "# display\n",
    "df_3.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Pandas Profiling to have a full view of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install -U pandas_profiling\n",
    "#pip install -U scipy\n",
    "import pandas_profiling as pp\n",
    "pp.ProfileReport(df_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Working without duplicates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1.1 selecting distinct observation from the record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#select distinct country, alpha_two_code, name from df_2\n",
    "dis_out = df_3[['country','alpha_two_code','name']].drop_duplicates()\n",
    "dis_out.head()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "We will like those records that were duplicated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1 = df_3[df_3['country']=='United States']\n",
    "t1.name.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_3[(df_3['country']=='United States') & (df_3['name']=='Highland Community College') ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1.2 Counting distinct records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#select country, count(country) from df_dist order by count(country)\n",
    "df_3['country'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = df_3[['country','alpha_two_code','name']].drop_duplicates()\n",
    "out['country'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1.3 Selecting Top 20 countries by number of Universities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#select country, count(country) as counts from df_dist order by counts desc limit 10\n",
    "df_3['country'].value_counts().rename_axis('country').reset_index(name='counts').head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1.4 selecting a variable and calculating the mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#select Age, avg(Discount) as AvgLoanAmount from df group by Age order by AvgLoanAMount desc Limit 10;\n",
    "df_2[['Team','Salary']].groupby('Team').mean().dropna().reset_index().head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#select max(Discount) from df where age = 20\n",
    "df[df.Age >= 20]['Discount'].max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.3.1 Inner Join using a Key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_inner = pd.merge(left=df, right=df_1, left_on='ClientID', right_on='ClientID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_inner.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(df_inner)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *** Selecting only the required columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_inner_1 = df_inner[['ClientID','LoanDate','LoanAmount','Term','LoanSeries','LoanPeriodID','RepaymentTerm','InterestAmount',\n",
    " 'Age','year_with_the_bank','default','predicted_scores','Defaulted_0','Defaulted_1']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_inner_1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_inner_1.to_csv('C:\\\\Users\\\\seune\\\\desktop\\\\base_scoring_1.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *** Selecting with multiple conditions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_sql = np.where((df['LoanDate']>='8/8/2017') & (df['LoanAmount'] > 50000) & (df['FT_Team'].str.startswith('S')))\n",
    "\n",
    "#Select * from df where LoanDate >= '8/8/2017' and LoanAmount > 50000 and Age > 30\n",
    "df_sql = np.where((df['LoanDate'] >= '8/8/2017') & (df['LoanAmount'] > 50000) & (df['Age'] > 50))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sql_1 = df.loc[df_sql]\n",
    "df_sql_1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sql_1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sorting dataframe\n",
    "df_3.sort_values(\"Team\", inplace = True)\n",
    "\n",
    "df_3.dropna(inplace = True)\n",
    "  \n",
    "# making boolean series for a team name\n",
    "filter1 = df_3[\"Team\"]==\"Atlanta Hawks\"\n",
    "  \n",
    "# making boolean series for age\n",
    "filter2 = df_3[\"Age\"]>=27\n",
    "  \n",
    "# filtering data on basis of both filters\n",
    "df_3.where(filter1 & filter2, inplace = True)\n",
    "\n",
    "#.dropna(inplace = True)\n",
    "  \n",
    "# display\n",
    "df_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#select * from df_3 where Team = 'Atlanta Hawks'\n",
    "\n",
    "# sorting dataframe\n",
    "df_3.sort_values(\"Team\", inplace = True)\n",
    "  \n",
    "# making boolean series for a team name\n",
    "filter = df_3[\"Team\"]==\"Atlanta Hawks\"\n",
    "  \n",
    "# filtering data\n",
    "df_3.where(filter, inplace = True)\n",
    "  \n",
    "# display\n",
    "df_3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *** Selecting only records with Wildcard "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_distinct.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *** Where a strings starts with U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#select all record from the dataframe where name like University\n",
    "df_json_sql = np.where((df_distinct['alpha_two_code'] == 'US') & (df_distinct['name'].str.startswith('U')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_json_sql_1 = df_distinct.loc[df_json_sql]\n",
    "df_json_sql_1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_json_sql_1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#select all record from the dataframe where name ends with 'Uni'\n",
    "df_json1 = np.where((df_distinct['alpha_two_code'] == 'US') & (df_distinct['name'].str.endswith('Uni')))\n",
    "df_json_1 = df_distinct.loc[df_json1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *** Where a string contains 'Uni' and 'Was'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#select all record from the dataframe where name like Uni and name like Was\n",
    "df_json_s = np.where((df_json['name'].str.contains('Uni')) & (df_json['name'].str.contains('Was')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_json_s_1 = df_json.loc[df_json_s]\n",
    "df_json_s_1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_json_s_a = df_json[df_json['name'].str.contains('Uni') & df_json['name'].str.contains('Was')]\n",
    "df_json_s_a.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *** Select Country, alpha_two_code and count distinct Universities in each of the countries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_json.loc['country','alpha_two_code']\n",
    "\n",
    "df_json[['country','alpha_two_code']].agg(['nunique','count','size'])\n",
    "\n",
    "\n",
    "#.agg(['nunique','count','size'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_json.groupby(['country','alpha_two_code']).agg(['count', 'nunique']).stack()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ****Case when "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def myfunc(Start_Date,End_Date):\n",
    "    Full_Year_Goal = None\n",
    "    if (Start_Date == '2014-07-27' or Start_Date == '2014-07-27') and End_Date == '2015-07-25':\n",
    "        Full_Year_Goal = 'Y'\n",
    "    elif (Start_Date == '2015-07-26' or Start_Date == '2015-07-27') and End_Date == '2016-07-30':\n",
    "        Full_Year_Goal = 'Y'\n",
    "    elif (Start_Date == '2016-07-31' and End_Date == '2017-07-29'):\n",
    "        Full_Year_Goal = 'Y'\n",
    "    elif (Start_Date == '2017-07-30' or Start_Date == '2017-07-31') and End_Date == '2018-07-28':\n",
    "        Full_Year_Goal = 'Y'\n",
    "    else:\n",
    "        Full_Year_Goal = 'N'\n",
    "    return Full_Year_Goal"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
